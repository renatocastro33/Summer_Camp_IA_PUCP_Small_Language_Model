{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca70c68-ab5b-4539-a3c2-1f1718fd22a6",
   "metadata": {},
   "source": [
    "# NanoChat GPT: Training a Small Chat Model\n",
    "\n",
    "In this notebook you will:\n",
    "- Inspect NanoChat's GPT architecture\n",
    "- Run a forward pass\n",
    "- Compute masked language modeling loss\n",
    "- Train a tiny chat model for a few steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e905f141-6063-4340-a205-612333756f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nanochat.gpt import GPT, GPTConfig\n",
    "from nanochat.tokenizer import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4449b585-45af-45b0-8982-65e00f53209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPTConfig(\n",
    "    vocab_size=tokenizer.get_vocab_size(),\n",
    "    n_layer=4,\n",
    "    n_head=4,\n",
    "    n_kv_head=4,\n",
    "    n_embd=256,\n",
    ")\n",
    "model = GPT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8d70807-035b-4e8e-8adc-7741e83d669f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nanochat has almost 36.7 MM parameters\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nanochat has almost {round(sum(p.numel() for p in model.parameters()) /1e6, 2)} MM parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cbd054-6046-4fae-a929-5b9746242760",
   "metadata": {},
   "source": [
    "<img src = \"LLM_Size.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b88fa7bb-6d98-496c-a50b-791bbb931fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is a transformer?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"A transformer is a neural network based on attention.\"}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bd97dc6-7af2-4f0f-96b2-a9b448a1a1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 20\n",
      "Loss tokens: 11\n"
     ]
    }
   ],
   "source": [
    "ids, loss_mask = tokenizer.render_conversation(conversation)\n",
    "\n",
    "print(\"Number of tokens:\", len(ids))\n",
    "print(\"Loss tokens:\", sum(loss_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c147c6c7-cef4-42ad-9587-1bcaf2963815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 65536])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input_ids = torch.tensor(ids).unsqueeze(0)  # (1, T)\n",
    "logits = model(input_ids)\n",
    "\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6514d41-fb3c-46a5-b18f-4c748d7d2af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.4196, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mask_t = torch.tensor(loss_mask).unsqueeze(0)\n",
    "\n",
    "targets = input_ids[:, 1:]\n",
    "logits = logits[:, :-1, :]\n",
    "\n",
    "loss_mask_t = loss_mask_t[:, 1:]\n",
    "\n",
    "log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "target_log_probs = log_probs.gather(-1, targets.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "loss = -(target_log_probs * loss_mask_t).sum() / loss_mask_t.sum()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66e593d5-f7f8-44cc-97fc-c52f482c9c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | loss 11.4196\n",
      "step 10 | loss 3.2912\n",
      "step 20 | loss 2.3380\n",
      "step 30 | loss 1.7654\n",
      "step 40 | loss 1.2236\n",
      "step 50 | loss 0.7951\n",
      "step 60 | loss 0.4974\n",
      "step 70 | loss 0.3161\n",
      "step 80 | loss 0.2135\n",
      "step 90 | loss 0.1551\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "for step in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(input_ids)\n",
    "    \n",
    "    logits = logits[:, :-1, :]\n",
    "    targets = input_ids[:, 1:]\n",
    "    mask = loss_mask_t\n",
    "    \n",
    "    log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "    loss = -(log_probs.gather(-1, targets.unsqueeze(-1)).squeeze(-1) * mask).sum() / mask.sum()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(f\"step {step} | loss {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "156d6a2f-2022-417c-a913-d5b2c3373385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:\n",
      "----------------------------------------\n",
      "A transformer is a neural network based on attention.<|assistant_end|>\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from nanochat.engine import Engine\n",
    "\n",
    "engine = Engine(model, tokenizer)\n",
    "\n",
    "print(\"Model output:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "input_ids = tokenizer.render_for_completion(conversation)\n",
    "\n",
    "output = \"\"\n",
    "for token_ids, token_mask in engine.generate(\n",
    "    input_ids,\n",
    "    max_tokens=50,\n",
    "    temperature=0.8,\n",
    "    top_k=40,\n",
    "):\n",
    "    text_piece = tokenizer.decode(token_ids)\n",
    "    print(text_piece, end=\"\", flush=True)\n",
    "    output += text_piece\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34293d7b-9c50-48c0-8ec1-fa021ad83f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
